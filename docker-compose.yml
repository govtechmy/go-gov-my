services:
  ## Database App Port: 5432 ##
  ps-postgres:
    image: postgres:13
    container_name: ps-postgres
    restart: always
    env_file:
      - .env
    environment:
      - POSTGRES_DB=${POSTGRESDB}
      - POSTGRES_USER=${POSTGRESUSER}
      - POSTGRES_PASSWORD=${POSTGRESPASSWORD}
    command:
      - -c
      - wal_level=logical
    ports:
      - 5432:5432
    volumes:
      - ps-postgres:/var/lib/postgresql/data
    networks:
      - my-network
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  ## Cache App Port: 6379 ##
  redis:
    image: redis:7.2
    container_name: redis
    restart: always
    ports:
      - 6379:6379
    networks:
      - my-network
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  ## Link Indexing App Port: 9200 ##
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.13.2
    container_name: elasticsearch
    restart: always
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - 9200:9200
    networks:
      - my-network
    volumes:
      - esdata:/usr/share/elasticsearch/data
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://elasticsearch:9200']
      interval: 3s
      timeout: 5s
      retries: 5
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'
    ulimits:
      memlock:
        soft: -1
        hard: -1
    mem_limit: 1g

  ## Filebeat Log Tail Port: 5044 ##
  filebeat:
    image: docker.elastic.co/beats/filebeat:7.13.2
    restart: always
    volumes:
      - filebeatdata:/usr/share/filebeat/data:rw
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - ./apps/redirect-server/logs:/usr/share/filebeat/logs:ro
    networks:
      - my-network
    depends_on:
      init-elasticsearch:
        condition: service_completed_successfully

  ## Go Log Collector Port: 5044 ##
  logstash:
    image: docker.elastic.co/logstash/logstash:7.13.2
    env_file:
      - .env
    ports:
      - '5044:5044'
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro
      - ./logstash.yml:/usr/share/logstash/config/logstash.yml:ro
    networks:
      - my-network

  # ## Data Propagation Port: 2181 ##
  zookeeper:
    image: quay.io/strimzi/kafka:0.44.0-kafka-3.8.0
    command:
      ['sh', '-c', 'bin/zookeeper-server-start.sh config/zookeeper.properties']
    hostname: zookeeper
    container_name: zookeeper
    environment:
      LOG_DIR: '/tmp/logs'
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 2181:2181
    networks:
      - my-network

  ## Kafka Broker Port: 9092 ##
  broker:
    image: quay.io/strimzi/kafka:0.44.0-kafka-3.8.0
    command:
      [
        'sh',
        '-c',
        'bin/kafka-server-start.sh config/server.properties --override listeners=$${KAFKA_LISTENERS} --override advertised.listeners=$${KAFKA_ADVERTISED_LISTENERS} --override zookeeper.connect=$${KAFKA_ZOOKEEPER_CONNECT} --override inter.broker.listener.name=$${KAFKA_INTER_BROKER_LISTENER_NAME} --override listener.security.protocol.map=$${KAFKA_LISTENER_SECURITY_PROTOCOL_MAP}',
      ]
    hostname: broker
    container_name: broker
    depends_on: [zookeeper]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENERS: PLAINTEXT://:29092,PLAINTEXT_HOST://:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      LOG_DIR: '/tmp/logs'
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    ports:
      - 9092:9092
      - 29092:29092
    networks:
      - my-network
    healthcheck:
      test:
        [
          'CMD-SHELL',
          '/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list',
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  ### Event Trigger Port: 8083 ##
  debezium:
    image: debezium/connect:2.6
    container_name: debezium
    environment:
      BOOTSTRAP_SERVERS: broker:29092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: connect_statuses
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_BOOTSTRAP_SERVERS: broker:29092
      CONNECT_REST_ADVERTISED_HOST_NAME: debezium
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: 1
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
    depends_on:
      broker:
        condition: service_started
      ps-postgres:
        condition: service_started
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:8083/connectors']
      interval: 3s
      timeout: 5s
      retries: 5
    ports:
      - 8083:8083
    networks:
      - my-network

  ## Debezium Connector Init Port: 8083 ##
  init-debezium-connector:
    image: curlimages/curl:8.8.0
    container_name: init-debezium-connector
    depends_on:
      debezium:
        condition: service_healthy
    volumes:
      - ./shell-script/init-debezium-connector.sh:/home/curl_user/init-debezium-connector.sh
    env_file:
      - .env
    environment:
      - POSTGRES_DB=${POSTGRESDB}
      - POSTGRES_USER=${POSTGRESUSER}
      - POSTGRES_PASSWORD=${POSTGRESPASSWORD}
    entrypoint: /home/curl_user/init-debezium-connector.sh
    networks:
      - my-network

  ## Elasticsearch Init Port: 9200 ##
  init-elasticsearch:
    image: curlimages/curl:8.8.0
    container_name: init-elasticsearch
    depends_on:
      elasticsearch:
        condition: service_healthy
    volumes:
      - ./shell-script/init-elasticsearch.sh:/home/curl_user/init-elasticsearch.sh
    entrypoint: /home/curl_user/init-elasticsearch.sh
    networks:
      - my-network

  ## Grafana Metrics Visualization Port: 3004 ##
  grafana-app:
    container_name: grafana-app
    build:
      context: .
      dockerfile: docker/Dockerfile.grafana
    ports:
      - 3004:3004
    volumes:
      - grafanadata:/var/lib/grafana
    networks:
      - my-network

  ## Metrics Reporter Port: 3005 ##
  prometheus-app:
    container_name: prometheus-app
    build:
      context: .
      dockerfile: docker/Dockerfile.prometheus
    ports:
      - 3005:3005
    volumes:
      - prometheusdata:/prometheus
    networks:
      - my-network

  ## Traces Reporter Port: 3006 ##
  jaeger-app:
    container_name: jaeger-app
    build:
      context: .
      dockerfile: docker/Dockerfile.jaeger
    volumes:
      - jaegerdata:/data
    ports:
      - 3006:3006
    networks:
      - my-network

  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop
    restart: always
    ports:
      - 9000:9000
    environment:
      KAFKA_BROKER_CONNECT: 'broker:29092'
    depends_on:
      - broker
    networks:
      - my-network

  init-kafka:
    image: quay.io/strimzi/kafka:0.44.0-kafka-3.8.0
    depends_on:
      - broker
    command: >
      sh -c "
      echo 'Waiting for Kafka to be ready...' &&
      sleep 30 &&
      echo 'Creating topics...' &&
      /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server broker:29092 --topic redirect_logs --partitions 3 --replication-factor 1 &&
      /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server broker:29092 --topic link_analytics --partitions 3 --replication-factor 1"
    networks:
      - my-network

networks:
  my-network:

volumes:
  ps-postgres:
  filebeatdata:
  grafanadata:
  prometheusdata:
  jaegerdata:
  esdata:
